
# 隐马尔可夫模型

## 一、假设前提

- **假设1：齐次马尔可夫假设**
  -  $t$ **时刻的状态量 $y_t$ 只和 $t-1$ 时刻的状态量$y_{t-1}$ 以及 $t$ 时刻的观测量 $x_t$ 有关，可以通过概率模型描述**
  -  **任意两相邻时刻间的状态量，共享相同的概率模型**
  -  **任意时刻的状态量和观测量之间，共享相同的概率模型**
- **假设2：观测独立性假设**
  - $t$ 时刻的观测量 $x_t$ 与其他时刻的观测量为相互独立的事件

![](https://raw.githubusercontent.com/shilang1220/imageBed/master/img/HMM_GRAPHIC.png)



## 二、基本思路

- 基本思路：

  - 采用生成模型，对观测量和状态量的联合概率分布建模
    - 与判别式模型不同，判别式模型是对 $P(y|x)$ 直接建模
    - 判别式模型的优势是模型简单、便于理解，缺点是只能做特定的回归、分类任务，无法做其他任务

- 两个阶段：

  - **概率模型生成阶段：**
    - 求解整个序列中观测量与状态量的联合概率分布 $P(x,y)$  ，即获得所有可能的x序列和y序列之间的联合概率分布函数，由于不同序列长度不同、内容不同，联合概率分布很难求解，因此， $HMM$ 用两个基本假设，简化了联合概率密度求解的方式
    - 具体来说，就是将整个序列的联合概率分布，在两个假设限定下，化解为所有时刻概率的乘积，并且所有时刻共享相同的概率模型
    - 最终，任意序列的联合概率分布模型求解问题，变成了对单一时刻的概率建模问题

  - **基于概率模型的任务推断阶段：**
    - 利用建立的联合概率分布模型，在不同的一致条件下，做很多判别式模型无法做的推断任务
    - 典型推断任务包括：
      - 样本生成（典型如：XXX）
      - 序列解码（典型如：NLP中的词性标注问题）
      - 噪声消除或图像重建（典型如：视频帧修复问题）
      - 动态滤波（典型如：卫星定位导航中的位置解算问题）



## 三、基本定义

- 定义： 
  - 观测(显状态)序列 $x = {x_1,x_2,..x_t,..x_T}$ ,  $x_i取值范围为[o_1..o_M]， \sum \limits_{k=1}^Mp(o_k) = 1$
    -  $T$ 为序列长度， $M$ 为观测量 $x$ 可能的取值个数
  - 状态(隐状态)序列 $y=y_1,y_2,..y_t,..y_T$ , $y_i取值范围为[i_1..i_N],\sum \limits_{k=1}^Np(i_k) = 1$
    -  $T$ 为序列长度（典型的 $HMM$ 多采用与观测序列等长）， $N$ 为状态量 $y$  可能的取值个数
  - 模型参数 
    -  $\pi = (\pi_1,\pi_2,..\pi_N)^T$ , 为初始状态概率向量， $\sum \limits_{i=1}^N\pi_i =1$
    -  $A=[p(y_t=i_q|y_{t-1}=i_p|)]_{N \times N}$ , 为状态转移概率矩阵，即隐状态从 $t-1$ 时刻的 $i_p$ 转移到 $t$ 时刻的 $i_q$ 的所有可能概率值构成的 $N \times N$ 矩阵，$\sum \limits_{q=1}^Na_{pq}=1$ 
    -  $B=[p(x_t=o_q|y_t=i_p|)]_{N \times M}$ , 为发射概率矩阵，即从 $t$ 时刻的隐状态  $i_p$ 发射命中 $t$ 时刻的显状态 $o_q$ 的所有可能概率值构成的 $N \times M$ 矩阵，$\sum \limits_{q=1}^Mb_{pq}=1$
    -  模型参数总量为： $N \times (N+ M+1)$ 
  - 样本和序列的标记方法
    -  第 $i$ 个样本的观测量和状态量标记为 $x^{(i)}$ ， $y^{(i)}$ 
    -  第 $i$ 个样本的第t个时刻的观测量和状态量标记为 $x_t^{(i)}$ ,　$y_t^{(i)}$
    -  设样本总数为： $Total$ 




## 四、学习（模型生成）过程

**（1）命题：** 

- 已知：样本集合 $X,Y = {<x^{(1)},y^{(1)}>,<x^{(2)},y^{(2)}>,..<x^{(N)},y^{(N)}>}$ ,  $N$ 为样本个数
- 求解：参数 $\lambda,\,即(\pi,A,B)$

**（2）联合概率的基本知识补充：**

- 依据联合概率的链式法则，$P(y_1,y_2,..y_n)= P(y_1)\prod \limits_{i=2}^nP(y_i|y_1，..y_{i-1}) $ 
- 如果事件 $y_1,y_2,..y_n$ 满足马尔科夫性，即 $P(y_i|y_1,..y_{i-1}) = P(y_i|y_{i-1})$ 
- 则联合概率可简化为： $P(y_1,y_2,..y_n)= P(y_1)\prod \limits_{i=2}^nP(y_i|y_{i-1})$ 

**（3） $HMM$ 的联合概率公式**

- 根据齐次马尔可夫假设和观测独立性假设，有：
  - 齐次马尔可夫假设： $ P(y_{t+1}|x_1,x_2,..x_{t-1},y_1,y_2,..y_t) = P(y_{t+1}|y_{t})$
  - 观测独立性假设： $ P(x_t|x_1,x_2,..x_{t-1},y_1,y_2,..y_{t}) = P(x_t|y_t)$
- 根据概率图模型，$HMM$ 属于有向图贝叶斯网络





**（4）利用极大似然法做参数估计的困境**

- 根据最大似然估计(发生的事件就是概率最大的事件)，且考虑到样本之间独立，有：

$$
\DeclareMathOperator*{\argmax}{arg max}
   \lambda_{MLE} =  \argmax_\lambda P(x,y|\lambda)=\argmax_\lambda\prod \limits_{i=1}^{Total}   P(x^{(i)},y^{(i)}|\lambda)
$$

  - 为简化运算，通常取其对数形式，即：

$$
\DeclareMathOperator*{\argmax}{arg max}
   \lambda_{MLE} =  \argmax_\lambda logP(x,y|\lambda)=\argmax_\lambda\sum \limits_{i=1}^{Total}logP(x^{(i)},y^{(i)}|\lambda)\\
   =argmax_\lambda\sum \limits_{i=1}^{Total}logP(x^{(i)},y^{(i)}|log\lambda)
$$

- 通常对于上述联合概率求导，就可以计算获得 $\lambda$ 。但对于 $HMM$  上述极大似然法做参数估计的难度太大

**（5） EM参数估计方法**

  - 用于解包含隐变量在内的参数估计问题，常采用具有递推特点的EM期望最大算法
    
  - 上式可以改写为：
    $$
    \DeclareMathOperator*{\argmax}{arg max}
    \lambda^{t+1}=\argmax \limits_\lambda \sum_1^{Total}logP(x,y|\lambda) P(y|x,\lambda^{t})
    $$
    



## 五、推断（模型应用）过程

### 5.1 如何估值(Evaluation）

- 问题：
  - 已知：  $\lambda$  
  - 求解：满足模型约束条件的观测序列和状态序列 ( ${x，y}$ )
- 方法：前向算法，后向算法
- 应用场景：自动样本生成、图像重建等
- 数学描述：
$$
P(x,y|\lambda)=\sum \limits_{y \in Y}P(x|y,\lambda)P(y|\lambda)\\
=\sum \limits_{y \in Y}P(x|y,\lambda)[\pi(a_{i1})\prod\limits_{t=2}^Ta_{y_{t-1},y_t}]\\
=\sum \limits_{y \in Y}[\prod\limits_{t=1}^Tb_{it}(y_t)][\pi(a_{i1})\prod\limits_{t=2}^Ta_{i-1}a_i]\\
=\sum \limits_{y \in Y}\pi(a_{i1})\prod\limits_{t=1}^Tb_{it}(y_t)\prod\limits_{t=2}^Ta_{i-1}a_i\\
$$

### 5.2 如何解码（Decoding）

- 问题：已知  $\lambda , \,x$ ， 求 $y$ 
- 思路：利用联合概率分布 $P(x,y)$ ，分别求出与序列 $x$ 对应的所有 $y$ 序列中，概率最大的那个 $y$ 序列
- 方法：动态规划算法求解最短路径，常用算法为Viterbi算法
- 应用场景：自然语言、视频等序列编码
- 当用于解码时：
  - 利用 $P(y|x) = \frac{P(x,y)}{P(x)} $ ，由于在确定的序列中，P(x)为一常数，所以 $P(y|x) \propto P(x,y)$ 
- 

### 5.3 如何滤波（Filtering）

- 问题：已知  $\lambda , \,x_1,x_2,..x_t$ , 求 $y_t$  
- 方法：
- 应用场景：online动态滤波
- 

### 5.4 如何平滑（Smoothing）

- 问题：已知  $\lambda , \,x_1,x_2,..x_t..x_N$ , 求 $y_t$  
- 方法：
- 应用场景：offline滤波

### 5.5 如何预测(Prediction)

- 问题：已知  $\lambda , \,x_1,x_2,..x_t$ ,  求 $y_{t+1},y_{t+2}..$  
- 方法：
- 应用场景：