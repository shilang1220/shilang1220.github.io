---
layout:     post
title:      "知识图谱中的NLP「 5 」"
subtitle:   "「 5. 词法分析---词性标注 」"
date:       2020-05-14 17:00:00
author:     "西山晴雪"
header-img: "img/post-bg-android.jpg"
categories: NLPChinese
tags:
    - 自然语言处理
    - NLP
    - 技术框架
    - 词法 
---

# 词法分析---词性标注

摘要：



## 一、词性标注问题

​		词性标注的目标是用一个单独的标签标记每一个词，该标签表示了用法和其句法作用，比如名词、动词、形容词等。在自然语言分析中，机器需要模拟理解语言。为了实现这一点，它必须在一定程度上能够了解自然语言的规则。它首先需要理解的是词，特别是每一个词的性质。它是一个名词还是一个形容词？如果它是一个动词的屈折形式，那么它的不定形式是什么，以及该屈折形式使用了什么对应的时态、人称和数？这个任务被称为词性标注（Part-of-Speech (PoS) tagging）。

John bought a book （John 买了一本书）

那么，有一个直接的方法：我们可以使用一本包含了所有这些词、它们的屈折形式和词性的信息的词典，以计算下面的输出：

John/专有名词

bought/动词过去式

a/限定词

book/名词

好吧，让我们抛开这样一个事实：语言是一种极为丰富的活性实体，因此我们永远无法知道所有的词。如我们所见，即使对最简单的句子而言，这种方法也没有用。bought 这个词也可作形容词，book 还可以是一个动词或名词。作为人类，我们通常可以解决这种歧义。但试试解读下面的句子：

Will Will will the will to Will? （可译为：Will 将会想把遗嘱给 Will 吗？）

## 二、词性标注的主要方法

- 基于规则或符号（symbolic）的方法
  - 符号方法由一组为不同语言现象建模的规则集合组成
  - 规则通常是由人工编写的，有时通过机器学习获得
  - 典型如：Brill 标注器

- 基于统计的（statistical）方法
  - 统计方法通常使用机器学习算法来学习语言现象
  - 统计方法将词性标注看作是一个序列标注问题
  - 基本思想：
    - 给定带有标注的词序列作为样本，学习下一个词的词性概率
    - 典型如：隐马尔可夫模型（HMM）、条件随机域（CRF）等模型

## 三、词性标注的用途

​	词性标注之所以被大家重视，主要是因为后续的高级处理不仅需要分词，还需要词性信息：

- 词义消歧：
  - 一词多用问题：一些词汇根据用法有很多种意思
  - 例如，“Please book my flight for Delhi”、 “I am going to read this book in the flight”中，“Book”在不同的上下文中出现，然而词性标签不同。第一句中“book”为动词，第二句中为名词。通过对词性标注的机器学习，有助于区分二者。
- 词特征抽取：
  - 当词汇作为特征时，一个学习模型可以学习到不同的词汇上下文，然而特征与词性连接起来，上下文就被保留了，因此得到了很强的特征。
  - 例如： “book my flight, I will read this book”，传统标签为 (“book”, 2), (“my”, 1), (“flight”, 1), (“I”, 1), (“will”, 1), (“read”, 1), (“this”, 1)，带有POS的标签为 (“book_VB”, 1), (“my_PRP$”, 1), (“flight_NN”, 1), (“I_PRP”, 1), (“will_MD”, 1), (“read_VB”, 1), (“this_DT”, 1), (“book_NN”, 1)
- 规范化和词形归并：
  - 词性标签是将词转化为其基本形式的基础
-  高效移除停止词：
  - 词性标签在移除停止词方面也非常有用。
  - 例如，有一些标签总是定义低频/较低重要性的词汇，例如：(IN – “within”, “upon”, “except”), (CD – “one”,”two”, “hundred”), (MD – “may”, “must” 等)

## 四、主要技术发展脉络

​		词性标注被认为是自然语言处理中不可分割的一部分，因为在某些情况下，如果不理解语义甚至语境的运用，就无法确定正确的词性。但词性标注也非常昂贵，尤其是当必须考虑到每个单词的多个词性可能性时，分析会变得很困难。

- 第一阶段：基于人工规则
  - 第一个用于计算机分析的主要英语语料库是布朗大学的Henry Kučera 和W. Nelson Francis在60年代中期开发的布朗语料库。Greene和Rubin随后花了许多年在布朗语料库上进行词性标记，他们使用了一个清单来手动列出语法规则。比如冠词和名词可以一起出现，但不能和动词一起出现。根据这个标注器，当时取得的正确率大概在70%。

- 第二阶段：机器学习的应用
  - 在20世纪80年代中期，隐马尔可夫模型（HMM）来消除词性的歧义
  - 2000年前后，基于最大熵、最大熵马尔可夫MEMM、条件随机场（CRF)、依赖性网络

- 第三阶段：神经网络的应用

  - 2010年后，Bi-LSTM模型、深度语境化词表征



## 五、未来发展分析

瓶颈
若将词性标注等不同任务分别开发不同的算法，在解决一整个问题时可能不方便结合；另外目前流行的深度学习需要大量的数据，这在词性标注问题上几乎是不可能的，因而即便是针对简单问题，深度学习也没有表现出明显的优势。此外，不同语言的标注难度也不同，如目前英文词性标注准确率可以达到97%左右，而中文的词性标注则要难许多。

未来发展方向
词性标注等语言处理任务是后续任何语言处理任务的基础，其重要性不言而喻。更高、更快、多语言的标注器都是可能的发展方向。

## 六、参考文献

1. Garside, R. (1987). The CLAWS Word-tagging System. In: R. Garside, G. Leech and G. Sampson (eds), The Computational Analysis of English: A Corpus-based Approach. London: Longman.
2. Church, K. W. (1988). A stochastic parts program and noun phrase parser for unrestricted text. ANLC '88: Proceedings of the second conference on Applied natural language processing. Association for Computational Linguistics Stroudsburg, PA.
3. DeRose, S. J. (1988). Grammatical category disambiguation by statistical optimization. Computational Linguistics 14(1): 31–39.
4. Toutanova, K.; Manning, C. D. (2000). Enriching the Knowledge Sources Used in a Maximum Entropy Part-of-Speech Tagger. In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC-2000), pp. 63-70.
5. McCallum, A., Freitag, D., and Pereira, F. C. N. (2000). Maximum entropy Markov models for information extraction and segmentation. In ICML 2000, pp. 591–598.
6. Lafferty, J. D., McCallum, A., and Pereira, F. C. N. (2001). Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In ICML 2001, Stanford, CA.
7. Toutanova, K. et al. (2003). Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network. In Proceedings of HLT-NAACL 2003, pp. 252-259.
8. Plank, B.; Søgaard, A.; & Goldberg, Y. (2016). Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.
9. Peters, M. E. et al. (2018). Deep contextualized word representations. arXiv:1802.05365v2.